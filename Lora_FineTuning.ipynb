{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4dD3ZlfcwfC",
    "outputId": "e69e861a-1059-4fff-e9db-f71646f87da7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kRIzG4ddpyb",
    "outputId": "64f9da91-7652-4ec7-f8fa-0df1a5556d6e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "79b4e023275444a6884fbe44642c263b",
      "4b9fc9a9f0914660ad6c75997782230b",
      "8b9d59d5f4da42488db448ef60979a97",
      "0c46013598c0409baed8f6651e39fce0",
      "374d783c6e42424da150219abd083a93",
      "0732ac42a5624964aaa48bf1589b5fe5",
      "72046ed2b912469388e93742324dbb6b",
      "78450e35e19245c6a29e72b20a7b266e",
      "a5ed127d1ec24eb4ab97af440954bc0e",
      "e271ac3e28444aaab6b9b066902845c5",
      "bbb3df45d0d04375920223b38c8f6e75",
      "5d3338d4eee945c4a97bf63cca95eaef",
      "371127733cbc4a5f9d9192fac774b236",
      "5057eeeeca7145558ade5db916cb3f9e",
      "d249ce8241ed47bfae6716ee71dd0566",
      "0e6af47929434ed39e9f511b518062e2",
      "bc8965c2398c411ca7b771d1bdbeee4f",
      "3723ded3da004efbabfb64c0e162fe51",
      "d5481ca91f54401fb8c13f9c0e9fe851",
      "62ffa323c7114d4f8176e888c675c6b9",
      "7678add0c4674d93888cc8c9dbbe9b84",
      "c537974db29b4948aab41294654ca670",
      "11adbc387d0c45479c405c85dbbf083a",
      "049a73f2b7474d8db5163a28c97c6392",
      "f8fcda421c3948788c78eb16afa111ab",
      "a5ffbc2db77945eea8449bc7d64ac124",
      "0621f0e2c5344d1cafb33d3ba21cc94e",
      "39a970bcdf8940a9b4eb788824e97fed",
      "78235c9c5d804f0bac6517b337d3df01",
      "bcf6e2c534c94ce09949398c5ecb6ee2",
      "2106cdd257644ec88059351a02970e46",
      "b1544d7e421342acaeadc00c76bf7fe4",
      "7f5454c26a4042e596e10d5859409726",
      "8ffb5e017b794273af002209900a9e44",
      "e3083dc2958a471f8ff4a62da9eff0b6",
      "047157ed6109462dae04faec57f764d3",
      "6514ddce25254d31b3deb6a950e10b1a",
      "50fcc74ea8b24deda2139bc9c6fe9407",
      "6e890377ab734c6d9236835a278082b7",
      "31bb8fbfd001456189cf5b31e788970a",
      "78044e608c864f2da08ed69d4d155551",
      "c0a68f09106b40d2bd73e835ba6e2a11",
      "e5c0bcbe3a634b26967a64e0ace58de6",
      "f24eb610061b4bc1a3a13ebf6b5ba733",
      "1947d5a9c3494b02b150e902fc295098",
      "79afb05fd35343119a53de36ff1a8ceb",
      "5599d5a79fdc44a6adb96227643ed07e",
      "c4d7be1ba113424aa787d6a9357f0898",
      "b4f20952ed1f488cb1b27a1fcf63aa95",
      "704828bb61ea40909415c2f256e27136",
      "91ad639f5ba345a59f15b518176febdf",
      "c71dcaadd47f43c094ca26ffbb1fe84e",
      "afa7b4675e214e56a93ec07f7441bf59",
      "00678972884841c1aa2de726d68d1c46",
      "3b709adc216e4860bb8402471ccf588c",
      "d0eb5c26ebd54672a73a25dd55fad584",
      "e838f7e4da7c430787049f60712ed559",
      "ece9bbaef0c14621af5a5c0a50771ee1",
      "56f346b2aebd4cf38a10e6e6e7e78943",
      "1f86aef801e14ad5ac4927a64846a053",
      "85e227261c0a4940895c6f7f2b282c5c",
      "1a00f7cb2995413fa929c91f8d540f2b",
      "9d50a0c5947c46bc80bf387e41d7a710",
      "ba20e12df3914d90921382b0446cef89",
      "ca40be060ea84b66a751d51a9ccb034d",
      "bd41627298f04d59ad9aaf2968cd47f6",
      "d978ef92ea48431289f3e31c6dc9824e",
      "2596d7e2de934412b6e0998607288396",
      "4a9559206b32465091244c3cf43ef46e",
      "b882b09ab2764e7585afe22c9f5d89d3",
      "9a9336e3c73b42c689aa628162c3c745",
      "15b4161cd4654912a2dac04d072bc9ad",
      "a6c9f02322224c04a8b92c7fe7c77e83",
      "4293bee969e64067ae1d04ac69736808",
      "ee3864e015d041f3a6f7dcb8b4a9483f",
      "0197f49cca77462581edae5e87890d64",
      "cdf7c38ac64f4c17bb2a82f4b3048260",
      "43b5aa6069104a9f9e86a1e612a8f6e3",
      "82452cd9291a4c75a229bf740c456bf2",
      "f46b2ef6ad7241218af93682bb6e52ab",
      "544b494baa0c4dcb9eb38578fce34db4",
      "b62d05f48e4b45959dcdb5a918425848",
      "b0f823dece7746bab255ea896ab4627f",
      "0963ba0fcdc347408df88e748273defa",
      "222127da708e4195a863e9c30e3c68f9",
      "ed0969b5315744559a537e79b53b61de",
      "c4d09d50ae14461ca88922cb10507cfa",
      "371d0634e4344bab97963ffd2f4cf136",
      "90b2001aba1145ec98ffdb9cee3a15d5",
      "b6e014a09732422fbc2677a236064d10",
      "23fd76e00d4d41cca73e77e8cca536ed",
      "3bc2d438b4a94d21b578f771ab10b7af",
      "1311763a09db48ac9cd5c9ccdd96deab",
      "eb2548f65f0c4fe39f583aac441c6a98",
      "c9b17ea6614a47348646d4579487bbcd",
      "f2dbfc2206df43d9940ea6dc3f7cedda",
      "ea67e93daa3147eeb4f856b14773d895",
      "0f2049efbe2f4d8aab1da351867efe45",
      "8d48995cf0b74e67a2b61eab0d0ed769",
      "95e47b48f571423a97eb97a87c9f8a5b",
      "50f4a2272a9d4ae9bb619c3b490faadd",
      "f1850f3a7ff04e87b07370a53ed22da0",
      "a19d61ae2547464294bddef581a773ac",
      "f035ef416c5b4a559628fa6fe5df8420",
      "36845b325e744dc9837a152c18fb8864",
      "8293b75185ca4fceb98e5949e07e74e9",
      "2815d947d70d4f3bbbdfcbafdfd43873",
      "c0b5c2c1ef3a48ffb27e767d7008cefb",
      "c9b5b267609047228850a7915f3f9adb",
      "f71e211fc72e4366b53bfecf395c7991",
      "049643649085405bb9676fc56ea8cf3d",
      "6e910be13ee54e36953a81e8ee47ce81",
      "27f8e6110adf4156baaab01518d8fe00",
      "20f295c4cc844281823d1ae67088d341",
      "78a931eafb7041999a5e89f687be7cdc",
      "99b2dbb2460a44aeb739f60bbbc8216c",
      "cdbc28fa34ca46ceaaab1126767a74b0",
      "1c079acbfeec42eabd7bcfb8ae974dd0",
      "f8d96b7a8a5a4a4bb14dd12042c525e0",
      "40521e7c9ba749c4b7653a16069dc9ce",
      "ddaa2b07eca34c448523fce3ae534e3e",
      "80af15bcdc0747109b2721df39c193a4",
      "4eb071f9c91f47c78654aafff3dd587c",
      "5b2d4c3f09cd4e578ca4f357c5dd2040",
      "1a6caab1223941fc94c10df884ea7ea2",
      "3aa174fe5a954a118307323c87d7ccce",
      "443a6d1520e34e51afe1652303c22466",
      "0d7e4ee442ed40a4879d724b9452b9aa",
      "82b3e2b332e446b1ab42ca952bb4225b",
      "0815363fae7243cd837f7821eb521ff4",
      "42b242fd0bc448baa1c8787ce29c8c90",
      "ee1b8829b9c4493fb2d319464ca2c12b",
      "6c883846c6e343e6972b81bbfc042c19",
      "b219e0fafe474f118347e994512d0204",
      "ff92b46a336140858def03d37af21321",
      "c417fa5010c34fc280c03920a63faf04",
      "f1cfde9e574246528f7724b847b91578",
      "4adb00e1494142ee890530f9122f0abe",
      "efb58ecea93a479dac382f860057bf62",
      "f9c77e7c89874696b1b91bebb38a2903",
      "f392c69cd23549648e7ca928a5a11bc4",
      "4218139f83994d78b270881f9c671a9b",
      "3dcd04f8066c4256874adfe4710ef07c",
      "d77987073cdc41699e81bf9518214e36",
      "5623ccefb61d43968fddd1118154d81c",
      "2b95871ab5484d2fa081ceb26b3eea52",
      "239543a554f44ef4a4d6cad294912515",
      "5891075f53bc4d18b0f6f78ff85d0cae",
      "530397db99094e08a1ae242b406dcf8f",
      "5cce50e0be8e42969fc1ece1366d3cc8",
      "f39b1e799bf447dc90f27264c571bf6d",
      "964f42874dc14b79a8a257e3c3cd8f48",
      "48450061948c4a27a0179dbf22b9bb45",
      "edbca6be65964241a0ec7fcc4eb80caa",
      "2184b2b76c4f4873b44c9562c9558809",
      "50e96d5485264ef2a9cb78ba72f8987b",
      "5416e247808d438cbcaf90681c16c9dc",
      "ddc7773fb8be4422b593d366d361091c",
      "f0c6e83068fa415284b1069ed547769f",
      "3f676214942345f1bfe96a44e7d25ba2",
      "bffbaad409e64ece9edc9f5ffdc32ac2",
      "b42dd3926fbc4753a37cb1e3a668511d",
      "89b7e203638d4368be14dcf7f24e68f8",
      "8629116cc2854ee7884d5fc8813f3e04",
      "074dc66c5e0f4362b491851fe1d98dc7"
     ]
    },
    "id": "rD4r7Yn0c_DX",
    "outputId": "ac38fd31-e3d2-45e5-dd57-325d67925dcf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, DDPMScheduler\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "DATASET_DIR = \"/content/drive/MyDrive/resized_images_dataset\"\n",
    "CAPTION = \"handwritten text\"\n",
    "OUTPUT_DIR = \"handwriting_lora\"\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 2\n",
    "LR = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float16 if device.type == \"cuda\" else torch.float32\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class HandwritingDataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        self.files = [\n",
    "            os.path.join(folder, f)\n",
    "            for f in os.listdir(folder)\n",
    "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "        ]\n",
    "\n",
    "        if len(self.files) == 0:\n",
    "            raise ValueError(\"‚ùå Dataset folder is empty\")\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.files[idx]).convert(\"RGB\")\n",
    "        return self.transform(image)\n",
    "\n",
    "dataset = HandwritingDataset(DATASET_DIR)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    safety_checker=None,\n",
    "    torch_dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "pipe.enable_attention_slicing()\n",
    "pipe.enable_vae_slicing()\n",
    "\n",
    "vae = pipe.vae\n",
    "unet = pipe.unet\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(MODEL_ID, subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    subfolder=\"text_encoder\",\n",
    "    torch_dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "vae.requires_grad_(False)\n",
    "text_encoder.requires_grad_(False)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"to_q\", \"to_v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "unet = get_peft_model(unet, lora_config)\n",
    "unet.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(unet.parameters(), lr=LR)\n",
    "\n",
    "print(\"üöÄ Starting LoRA fine-tuning...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for images in tqdm(dataloader):\n",
    "        images = images.to(device, dtype=dtype)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            latents = vae.encode(images).latent_dist.sample()\n",
    "            latents = latents * 0.18215\n",
    "\n",
    "        noise = torch.randn_like(latents)\n",
    "        timesteps = torch.randint(\n",
    "            0,\n",
    "            scheduler.config.num_train_timesteps,\n",
    "            (latents.shape[0],),\n",
    "            device=device\n",
    "        ).long()\n",
    "\n",
    "        noisy_latents = scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "        tokens = tokenizer(\n",
    "            [CAPTION] * latents.shape[0],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=77,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_hidden_states = text_encoder(\n",
    "                tokens.input_ids\n",
    "            ).last_hidden_state\n",
    "\n",
    "        noise_pred = unet(\n",
    "            noisy_latents,\n",
    "            timesteps,\n",
    "            encoder_hidden_states\n",
    "        ).sample\n",
    "\n",
    "        loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "unet.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "print(\"\\n‚úÖ LoRA fine-tuning complete\")\n",
    "print(f\"üìÅ Saved to: {OUTPUT_DIR}\")\n",
    "print(\"üé® Ready for handwriting generation!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPH2NDZLQ_23"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
